# Copy this file to .env and update with your actual settings

# ===== Google Cloud / BigQuery Configuration =====
# Path to your Google Cloud service account key file
GOOGLE_APPLICATION_CREDENTIALS=./credentials/google-credentials.json

# Your GCP Project ID
GCP_PROJECT=your-gcp-project-id

# BigQuery Dataset (default target)
BIGQUERY_DATASET=ecommerce_analytics_dev

# ===== DBT Configuration =====
# DBT project directory (use /app for Docker, actual path for local)
DBT_PROJECT_DIR=/app

# DBT profiles directory
DBT_PROFILES_DIR=/root/.dbt

# ===== OpenAI Configuration (for LangChain Agent) =====
# Your OpenAI API key for using GPT models with the agent
OPENAI_API_KEY=sk-your-openai-api-key-here

# ===== NOTES =====
# 1. Create credentials/google-credentials.json with your service account key
# 2. Update GCP_PROJECT with your actual Google Cloud project ID
# 3. Update BIGQUERY_DATASET with your target dataset name
# 4. For Docker: paths are container paths (/app, /root/.dbt)
# 5. For local: use actual file system paths
